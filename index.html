<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Ruirui Li's Homepage</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 900px;
      margin: auto;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      flex-wrap: wrap;
      margin-bottom: 30px;
    }
    header .info {
      flex: 1;
    }
    header h1 {
      font-size: 2em;
      margin: 0;
    }
    header h3 {
      font-weight: normal;
      color: #666;
    }
    header img {
      max-width: 260px;
      border-radius: 50%;
      margin-top: 15px;
    }
    h2 {
      border-bottom: 2px solid #eee;
      padding-bottom: 6px;
      margin-top: 40px;
      font-size: 1.5em;
      color: #444;
    }
    details summary {
      font-weight: bold;
      cursor: pointer;
      margin: 8px 0;
    }
    details[open] summary {
      color: #0056b3;
    }
    ol, ul {
      padding-left: 20px;
    }
    .award {
      background: #f9f9f9;
      padding: 6px 12px;
      border-radius: 8px;
      display: inline-block;
      margin: 5px 0;
    }
    footer {
      margin-top: 40px;
      text-align: center;
      font-size: 0.9em;
      color: #666;
      border-top: 1px solid #ddd;
      padding-top: 10px;
    }
    @media (max-width: 768px) {
      body {
        padding: 15px;
      }
      header {
        flex-direction: column;
        text-align: center;
      }
      header img {
        margin: 15px auto 0;
      }
    }
  </style>
</head>
<body>

<header>
  <div class="info">
    <h1>Ruirui Li</h1>
    <h3>Staff Machine Learning Scientist & Engineer</h3>
    <p><i class="fa fa-envelope"></i> goldenbearray at gmail dot com</p>
  </div>
  <div class="photo">
    <img src="rrli.JPG" alt="Ruirui Li portrait">
  </div>
</header>

<h2>About Me</h2>
<p>
  I am a staff machine learning scientist & engineer at Coupang specializing in applied machine learning and deep learning, with a focus on pricing, product mapping and monitoring. 
  Before that, I worked on search query understanding, query rewriting, related and trending searches, speaker verification/identification, and leveraging large language models (LLMs) for shopping and evaluation (LLM-as-a-Judge) at Amazon.
  I earned my Ph.D. from UCLA under the guidance of Prof. Wei Wang, my MPhil from The University of Hong Kong, where I worked with Prof. Ben Kao, and my B.S. from Nanjing University.
</p>

<h2>Experiences</h2>
<ul>
  <li><strong>2025 – Now</strong> Staff Machine Learning Scientist & Engineer, <strong>Coupang</strong></li>
  <li><strong>2022 – 2025</strong> Senior Applied Scientist, <strong>Amazon Search</strong></li>
  <li><strong>2019 – 2022</strong> Applied Scientist, <strong>Amazon Alexa</strong></li>
  <li><strong>2013 – 2019</strong> Research Assistant, <strong>University of California, Los Angeles</strong></li>
</ul>

<h2>Publications</h2>

<details open>
  <summary>2025</summary>
  <ol>
    <li>Yunzhe Qi, Jinjin Tian, Tianci Liu, <strong>Ruirui Li</strong>, Tianxin Wei, Hui Liu, Xianfeng Tang, Monica Cheng, Jingrui He, <em>Learning to Instruct: Fine-Tuning a Task-Aware Instruction Optimizer for Black-Box LLMs</em>, (<strong>EMNLP'25</strong>), Suzhou, China.</li>
    <li>Tianci Liu, <strong>Ruirui Li</strong>, Haoyu Wang, Yunzhe Qi, Hui Liu, Xianfeng Tang, Tianqi Zheng, Qingyu Yin, Monica Cheng, Jun Huan, Jing Gao, <em>Unlocking Efficient, Scalable, and Continual Knowledge Editing with Basis-Level Representation Fine-Tuning</em>, (<strong>ICLR'25</strong>), Singapore.</li>
    <li>Tianci Liu, <strong>Ruirui Li</strong>, Zihan Dong, Hui Liu, Xianfeng Tang, Qingyu Yin, Linjun Zhang, Haoyu Wang, Jing Gao, <em>Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing</em>, (<strong>ICML'25</strong>), Vancouver.</li>
  </ol>
</details>

<details>
  <summary>2023 & 2024</summary>
  <ol>
      <li>Haoyu Wang, Tianci Liu, <strong>Ruirui Li</strong>, Monica Cheng, Tuo Zhang, Jing Gao, RosaLora: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning, (<strong>EMNLP'24</strong>), Miami, 2024.</li>
  		<li>Haoyu Wang, <strong>Ruirui Li</strong>, Haoming Jiang, Jinjin Tian, Zhengyang Wang, Chen Luo, Xianfeng Tang, Monica Xiao, Tuo Zhao, Jing Gao. BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering, (<strong>EMNLP'24</strong>), Miami, 2024.</li>
  		<li>Haoyu Wang, <strong>Ruirui Li</strong>, Zhengyang Wang, Xianfeng Tang, Danni Zhang, Jasha Droppo, Monica Cheng, Ying Yin, Suhang Wang, Jing Gao, A Lightweight Representation Quantization Framework for Long-tail Data, (<strong>ICDE'24</strong>), Utrecht, Netherlands, 2024.</li>
  		<li>Tianxin Wei, Bowen Jin, <strong>Ruirui Li</strong>, Hansi Zeng, Zhengyang Wang, Jianhui Sun, Qingyu Yin, Hanqing Lu, Suhang Wang, Jingrui He, Xianfeng Tang, Towards Universal Multi-Modal Personalization: A Language Model Empowered Generative Paradigm, (<strong>ICLR'24</strong>), Vienna, Austria, 2024. </li>
  		<li>Xiusi Chen, Hongzhi Wen, Sreyashi Nag, Chen Luo, Qingyu Yin, <strong>Ruirui Li</strong>, Zheng Li, Wei Wang, IterAlign: Iterative Constitutional Alignment of Large Language Models, (<strong>NAACL'24</strong>), Mexico City, Mexico, 2024. </li>
  		<li>Bowen Jin, Hansi Zeng, Guoyin Wang, Xiusi Chen, Tianxin Wei, <strong>Ruirui Li</strong>, Zhengyang wang, Zheng Li, Yang Li, Hanqing Lu, Suhang wang, Jiawei Han, Xiafeng Tang, Language Models as Semantic Indexers, (<strong>ICML'24</strong>), Vienna, Austria, 2024.</li>
  		<li>Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, <strong>Ruirui Li</strong>, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han, Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs, (<strong>ACL Findings</strong>), Bangkok, Thailand, 2024.</li>
  		<li>Kewei Cheng, Jingfeng Yang, Zhengyang Wang, Binxuan Huang, Haoming Jiang, <strong>Ruirui Li</strong>strong>, Shiyang Li, Zheng Li, Yifan Gao, Xian Li, Bing Yin, Yizhou SunInductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs, LightToken: a Task and Model-agnostic Lightweight Token Embedding Framework for Pre-trained Language Models, (<strong>ACL'24</strong>), Bangkok, Thailand, 2024.</li>
  		<li>Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing Lu, Zhengyang Wang, <strong>Ruirui Li</strong>, Zhen Li, Monica Xiao Cheng, Rahul Goutam, Haiyang Zhang, Karthik Subbian, Suhang Wang, Yizhou Sun, Jiliang Tang, Bing Yin, Xianfeng Tang, Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation, (<strong>NeurIPS'23</strong>), New Orleans, 2023.</li>
  		<li>Haoyu Wang, <strong>Ruirui Li</strong>, Haoming Jiang, Zhengyang Wang, Xianfeng Tang, Bin Bi, Monica Cheng, Bing Yin, Yaqing Wang, Tuo Zhao, Jing Gao, LightToken: a Task and Model-agnostic Lightweight Token Embedding Framework for Pre-trained Language Models, (<strong>KDD'23</strong>), Long Beach, 2023.</li>
  </ol>
</details>

<details>
  <summary>2022 & 2021</summary>
  <ol>
    <li> Metehan Cekic, <strong>Ruirui Li</strong>, Zeya Chen, Yuguang Yang, Andreas Stolcke, Upamanyu Madhow. Self-supervised Speaker Recognition Training Using Human-Machine Dialogues, (<strong>ICASSP'22</strong>), Singapore, 2022.</li>
		<li> Xin Zhang*, Minho Jin*, Roger Cheng, <strong>Ruirui Li</strong>, Eunjung Han, Andreas Stolcke. Contrastive-Mixup Learning for Improved Speaker Verification, (<strong>ICASSP'22</strong>), Singapore, 2022.</li>
		<li> <strong>Ruirui Li</strong>, Chelsea J.-T. Ju, Zeya Chen, Hongda Mao, Oguz Elibol, and Andreas Stolcke, Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition. (<strong>INTERSPEECH'21</strong>), Brno, Czechia, 2021.</li>
		<li> Haici Yang, Hongda Mao, <strong>Ruirui Li</strong>, Chelsea J.T. Ju, and Oguz Elibol, Non-local Convolutional Neural Networks (NLCNN) for Speaker Recognition. (<strong>INTERSPEECH'21</strong>), Brno, Czechia, 2021. [Submitted]</li>
		<li> Tianxin Wei*, <strong>Ruirui Li</strong>*, and Oguz Elibol, Adversarial Multi-task Learning for Speaker Recognition with Self-supervised Reconstructions. (<strong>INTERSPEECH'21</strong>), Brno, Czechia, 2021. [Submitted]</li>
		<li> Jie Pu, Yuguang Yang*, <strong>Ruirui Li</strong>*, and Oguz Elibol, Scaling Effect of Self-Supervised Speech Models. (<strong>INTERSPEECH'21</strong>), Brno, Czechia, 2021.</li>
  </ol>
</details>

<details>
  <summary>2020 & before</summary>
  <ol>
    <li> <strong>Ruirui Li</strong>, Jyun-Yu Jiang, Chu-Cheng Hsieh, and Andreas Stolcke, Speaker Identification for Household Scenarios with Self-attention and Adversarial Training. (<strong>InterSpeech'20</strong>), Shanghai, China, 2020. [<a href="https://www.amazon.science/publications/speaker-identification-for-household-scenarios-with-self-attention-and-adversarial-training">paper</a>]</li>
		<li> <strong>Ruirui Li</strong>, Jyun-Yu Jiang,, Hongda Mao, Chu-Cheng Hsieh, and Wei Wang, Bridging Mixture Density Networks with Meta-learning for Automatic Speaker Identification. (<strong>ICASSP'20</strong>), Barcelona, Spain, 2020. [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9054111">paper</a>, <a href="https://2020.ieeeicassp-virtual.org/presentation/poster/bridging-mixture-density-networks-meta-learning-automatic-speaker">video</a>]</li>
		<li> <strong>Ruirui Li</strong>, Xiusi Chen, and Wei Wang, Few-shot Learning for New User Recommendation in Location-based Social Networks. (<strong>WWW'20</strong>), Taipei, Taiwan, 2020. [<a href="https://dl.acm.org/doi/pdf/10.1145/3366423.3379994">paper</a>, <a href="https://www.youtube.com/watch?v=tklYSL5TjN4&list=PLJNwhMK_V7EyZCUt6SjW4JthoM9-QiHMZ&index=21">video</a>]</li>
		<li> Huaxiu Yao, Zhiqiang Tao, Yaliang Li, Bolin Ding, <strong>Ruirui Li</strong>, and Zhenhui Li, Automated Relational Meta-learning. (<strong>ICLR'20</strong>), Addis Ababa, Ethiopia 2020. [<a href="https://openreview.net/forum?id=rklp93EtwH">paper</a>]</li>
		<li> Tianxin Wei, Ziwei Wu, <strong>Ruirui Li</strong>, Ziniu Hu, Fuli Feng, Xiangnan He, Yizhou Sun, and Wei Wang, Fast Adaptation for Cold-start Collaborative Filtering with Meta-learning. (<strong>ICDM'20</strong>), Sorrento, Italy, 2020.</li>
                <li> <strong>Ruirui Li</strong>, and Wei Wang, Adversarial Learning to Compare: Self-Attentive Prospective Customer Recommendation in Location-baesd Social Networks. (<strong>WSDM'20</strong>), Houston, Texas, 2020. [<a href="https://dl.acm.org/doi/pdf/10.1145/3336191.3371841">paper</a>]</li>
		<li> <strong>Ruirui Li</strong>, Jyun-Yu Jiang, Jiahao Liu, Chu-Cheng Hsieh, and Wei Wang, Automatic Speaker Recognition with Limited Data. (<strong>WSDM'20</strong>), Houston, Texas 2020. [<a href="https://dl.acm.org/doi/pdf/10.1145/3336191.3371802">paper</a>]</li>
		<li> <strong>Ruirui Li</strong>, Liangda Li, Yunhong Zhou, and Wei Wang, Click Feedback-Aware Query Recommendation Using Adversarial Examples. (<strong>WWW'19</strong>), San Francisco, CA, 2019. [<a href="https://dl.acm.org/doi/pdf/10.1145/3308558.3313412">paper</a>]</li>
		<li> <strong>Ruirui Li</strong>, Jyun-Yu Jiang, Chelsea J.-T. Ju, and Wei Wang, CORALS: Who are My Potential New Customers? Tapping into the Wisdom of Customers' Decisions. (<strong>WSDM'19</strong>), Melbourne, Australia, 2019. [<a href="https://dl.acm.org/doi/pdf/10.1145/3289600.3290995">paper</a>]</li>
		<li> <strong>Ruirui Li</strong>, Jyun-Yu Jiang, Chelsea J.-T, Cheryl Flynn, Wen-ling Hsu, Jia Wang, Wei Wang, and Tan Xu, Enhancing Response Generation Using Chat Flow Identification. (<strong>KDD'18 Workshop</strong>), London, Aug. 2018.</li> 
                <li> Zijun Xue, Mingda Li, and <strong>Ruirui Li</strong>, Recent Progress in Conversational AI. (<strong>KDD'18 Workshop</strong>), London, Aug. 2018.</li> 
		<li> Chelsea J.-T. Ju, <strong>Ruirui Li</strong>, Zhengliang Wu, Jyun-Yu Jiang, Zhao Yang, and Wei Wang, Fleximer: Accurate Quatification of RNA-Seq via Variable-Length k-mers. (<strong>ACM BCB'17</strong>), Boston, 2017</li>
		<li> <strong>Ruirui Li</strong>, Xinxin Huang, Shuo Song, Jia Wang, and Wei Wang, Towards customer trouble tickets resolution automation in large cellular services. (<strong>Mobicom'16</strong>), New York, 2016.</li>
		<li>Liuli Chen, Jennifer Zhang, Chelsea J.-T. Ju, <strong>Ruirui Li</strong>, Wenchao Yu, and Wei Wang, Skimdiff: Transcript-level differential analysis of RNA-Seq data. (<strong>HitSeq'15</strong>), Dublin, Ireland. 2015.</li>
		<li><strong>Ruirui Li</strong>, and Wei Wang, REAFUM: Representative Approximate Frequent Subgraph Mining. (<strong>SDM'15</strong>), Vancouver, Apr. 2015. [<a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611974010.85">paper</a>]</li>
		<li><strong>Ruirui Li</strong>, Ben Kao, Bin Bi, Reynold Cheung, and Eric Lo, DQR: A probabilistic approach to diversified query recommendation. (<strong>CIKM'12</strong>), Hawaii, Oct. 2012. [<a href="https://dl.acm.org/doi/pdf/10.1145/2396761.2396768">paper</a>]</li>
  </ol>
</details>

<h2>Selected Awards</h2>
<ul>
  <li class="award"><strong>WSDM Travel Grant</strong>, SIGIR, 2019, 2020</li>
  <li class="award"><strong>Yahoo! FREP Award</strong>, advisor: Wei Wang, 2019</li>
  <li class="award"><a href="https://engineeringblog.yelp.com/2018/01/yelp-dataset-challenge-round9-winner.html"><strong>Yelp Dataset Challenge Winner</strong></a>, Round 9, 2017</li>
  <li class="award"><strong>Department Fellowship</strong>, UCLA, 2013</li>
  <li class="award"><strong>Full Postgraduate Fellowship</strong>, University of Hong Kong, 2010</li>
  <li class="award"><strong>Research Conference Grant</strong>, University of Hong Kong, 2012</li>
  <li class="award"><strong>Outstanding Undergraduates</strong>, Nanjing University, 2010</li>
</ul>

<footer>
  <p>© 2025 Ruirui Li • Last updated: June 1, 2025</p>
</footer>

</body>
</html>
